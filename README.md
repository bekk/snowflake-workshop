# Workshop: Introduksjon til Snowflake ‚ùÑÔ∏è

Velkommen til Snowflake-workshop! De neste to timene skal vi bryne oss p√• innhenting, transformering og plotting av [tilsynsdata](https://hotell.difi.no/?dataset=mattilsynet/smilefjes/tilsyn) fra Digitaliseringsdirektoratet. Dette er en vurdering av over 3500 restauranter i Norge p√• parametre som lokaler, math√•ndtering, merking og lignende. V√•rt m√•l er √• ta i bruk geodata fra Kartverket for √• visualisere hvilke kommuner i Norge som har - og eventuelt _ikke_ har - restaurantene sine helt p√• stell üòÄ ü§î üò©

## DEL 1: Kobling mot Google Cloud Storage üíæ

Logg inn i [Snowflake](https://sc96841.europe-west4.gcp.snowflakecomputing.com/console/login#/) med brukernavn og passord du har blitt tildelt og naviger deg til **Projects -> Worksheets** og lag et nytt worksheet i h√∏yre hj√∏rne. N√• er du klar til √• utvikle i ditt eget arbeidsomr√•de!

> **Tips üí°** N√•r vi jobber i en Snowflake Worksheet er det ikke n√∏dvendig √• slette cellene etter de er kj√∏rt. Du kan heller markere de linjene du √∏nsker skal kj√∏re, s√• har du ogs√• historikken med deg til senere oppgaver.  

### Oppgave 1.1: Lag database og skjema 
Det f√∏rste du m√• gj√∏re er √• lage en egen database og et skjema (datasett) p√• formatet `ditt_navn`_database/schema slik som i kodesnutten under. Bytt med ditt eget navn og kj√∏r cellene i Snowflake. 

```sql
CREATE DATABASE ditt_navn_database; 
CREATE SCHEMA ditt_navn_schema;
```

Naviger deg til **Database** i panelet til venstre og kj√∏r refresh. N√• vil du forh√•pentligvis se at din nye database og skjema er opprettet.

<img src=https://github.com/bekk/snowflake-workshop/assets/29883261/6f4f1fac-94f7-43f5-94c0-6bd47b4e4a25 width=250 />

Det er slitsomt √• m√•tte spesifisere hele stien hver gang vi oppretter en tabell. Heldigvis kan du slippe dette ved √• sette hvilken kontekst du √∏nsker √• v√¶re i (alts√•, hvilken database og hvilket skjema du vil bruke). I filen kan du navigere deg i venstre hj√∏rne og sette database og skjema som vi akkurat lagde.

<img src=https://github.com/bekk/snowflake-workshop/assets/29883261/baac22e4-51e6-415c-98fb-02cf5ba46c44 width=400 />


Nok snikksnakk, la oss hente data fra GCP!

### Oppgave 1.2: Last inn data fra GCS-b√∏tte ü™£

N√• skal vi hente data fra `snowflake-ws-raw-data`-b√∏tta som ligger i [GCP](https://console.cloud.google.com/storage/browser?project=snowflake-workshop&prefix=&forceOnBucketsSortingFiltering=true). For √• gj√∏re dette er vi n√∏dt til √• opprette en konfigurasjonsenhet som brukes for √• integrere Snowflake med eksterne lagringstjenester (som Google Cloud Storage). Denne enheten kalles for `storage integration object` og oppretter blant annet en egen service account (maskinbruker) som vi kan gi tilgang til i b√∏tta v√•r. Kodesnutten under sier at vi √∏nsker √• lage et eksternt volum i GCS som har tilgang til en gitt sti. 

> **NB:** Det g√•r bare an √• sette opp √©n integrasjon per b√∏tte. Denne er allerede satt opp for dere, s√• dere trenger ikke kj√∏re kodesnutten under!

```sql
CREATE STORAGE INTEGRATION august_gcp_integration
    type = external_stage
    storage_provider = GCS 
    enabled = true 
    storage_allowed_locations = ('gcs://snowflake-ws-raw-data/');
```

N√• kan vi hente ut den genererte maskinbrukeren ved √• kj√∏re:

```sql
DESC STORAGE INTEGRATION august_gcp_integration;
```

Her ser vi at vi har f√•tt en maskinbruker, `STORAGE_GCP_SERVICE_ACCOUNT`, som vi kan gi tilgang til i b√∏tta. Dette er ogs√• allerede gjort, men du kan verifisere det ved √• navigere deg til [**Permissions**](https://console.cloud.google.com/storage/browser/snowflake-ws-raw-data;tab=permissions?forceOnBucketsSortingFiltering=true&project=snowflake-workshop&prefix=&forceOnObjectsSortingFiltering=false)-fanen i b√∏tta og se at maskinbrukeren har rettigheten `Storage Admin`.

S√• lett var det - n√• har vi muligheten til √• autentisere oss mot b√∏tta og hente ut dataen üöÄ

### Oppgave 1.3: Lag mellomledd for kildedata og datavarehus

Det siste vi trenger √• lage for √• hente data er et `stage object`. Dette er et omr√•de som brukes til midlertidig lagring av r√•datafiler f√∏r de lastes inn i Snowflake-databaser. Det fungerer som et mellomledd mellom kildedataene og datavarehuset v√•rt. For √• hente dataen m√• vi ta i bruk `storage integration`-objektet vi nettopp lagde ved √• kopiere og kj√∏re kodesnutten under:

```sql
CREATE STAGE gcp_data
    storage_integration = august_gcp_integration
    url = 'gcs://snowflake-ws-raw-data/';
```

Verifiser at dette funket ved √• kj√∏re `list @gcp_data;`. F√•r du opp fire filer, er vi _endelig_ klare til √• kopiere data inn i Snowflake. 


## DEL 2: Hent CSV-data for tilsyn og postnummer üì´

### Oppgave 2.1: Kopier data fra stage til tabell
N√• skal vi gj√∏re oss klare for √• laste inn data. F√∏rst er vi n√∏dt til √• lage et fil-format som matcher CSV-formatet. 
√Öpne `postnummer.csv` og `tilsyn.csv` i [b√∏tta](https://console.cloud.google.com/storage/browser/snowflake-ws-raw-data;tab=objects?forceOnBucketsSortingFiltering=true&project=snowflake-workshop&prefix=&forceOnObjectsSortingFiltering=false) for √• se hvilke verdier du m√• erstatte i kodesnutten under: 

```sql
CREATE FILE FORMAT csv_format
    type = csv 
    field_delimiter = <sett_inn_separasjonstegn>
    skip_header = <sett_inn_antall_rader_som_m√•_hoppes_over>;
```

I tillegg m√• vi initiere tabellen v√•r, `tilsyn`, med riktig antall kolonner og type. Dette er en d√∏ll prosess √• gj√∏re for h√•nd (ChatGPT fikset det for meg), s√• bare kopier og kj√∏r snutten under:

```sql
CREATE TABLE tilsyn (
    tilsynsobjektid VARCHAR,
    orgnummer VARCHAR,
    navn VARCHAR,
    adrlinje1 VARCHAR,
    adrlinje2 VARCHAR,
    postnr VARCHAR,
    poststed VARCHAR,
    tilsynid VARCHAR,
    sakref VARCHAR,
    status INT,
    dato VARCHAR,
    total_karakter INT,
    tilsynsbesoektype INT,
    tema1 VARCHAR,
    tema1_nn VARCHAR,
    karakter1 INT,
    tema2_no VARCHAR,
    tema2_nn VARCHAR,
    karakter2 INT,
    tema3_no VARCHAR,
    tema3_nn VARCHAR,
    karakter3 INT,
    tema4_no VARCHAR,
    tema4_nn VARCHAR,
    karakter4 INT
);
```

Til slutt kopierer vi dataen _fra_ stage-objektet v√•rt _til_ den nylig opprettede tabellen v√•r. Merk at n√•r vi tar i bruk stage-objektet v√•rt, s√• slipper vi ogs√• √• fore inn hele URL-en. Siden dataen ogs√• (muligens) inneholder noen korrupte rader, slenger vi p√• `on_error=continue` for at opplastingen skal hoppe over disse radene og fortsette innlastningen. Kj√∏r og kopier:

```sql
COPY INTO tilsyn 
FROM @gcp_data/csv/tilsyn.csv
file_format=csv_format
on_error=continue;
```

N√•r snutten er ferdigkj√∏rt kan vi se at det var seks rader som var feilformatert. Det bryr vi oss ikke s√• mye om i denne workshopen. 

Kj√∏r en sp√∏rring p√• tabellen for √• sjekke at dataen er korrekt lastet inn. 

### Oppgave 2.2: Transformer tilsynstabellen

Det er et par ting med den opprinnelige r√•dataen som ikke passer v√•rt form√•l. Lag derfor en sp√∏rring og skriv den til en ny tabell, `tilsyn_transformert`, som inneholder f√∏lgende:
1. `navn, orgnummer, postnr, poststed, total_karakter`-kolonnene p√• vanlig format
2. Sette verdier fra `karakter1` til kolonne `rutiner_og_ledelse`, `karakter2` til `lokaler_og_utstyr`, `karakter3` til `mathandtering_og_tilberedning` og `karakter4` til `merking_og_sporbarhet`
3. Omgj√∏re dato-strengen p√• formatet 'DDMMYYYY' til dato 
4. Kj√∏r en sp√∏rring som verifiserer at dataen ser korrekt ut.

<details>
  <summary>üö® L√∏sningsforslag</summary>
  
  ```sql
  CREATE TABLE tilsyn_transformert as 
      select 
          navn, 
          orgnummer,
          postnr, 
          poststed,
          total_karakter,
          karakter1 as rutiner_og_ledelse,
          karakter2 as lokaler_og_utstyr,
          karakter3 as mathandtering_og_tilberedning,
          karakter4 as merking_og_sporbarhet,
          TO_DATE(dato, 'DDMMYYYY') as dato
      from tilsyn;
  ```

</details>


### Oppgave 2.3: Hent inn postnummer-data

I neste del av workshopen skal vi f√• inn geodata for kommuner. Problemet v√•rt er at det eneste vi har √• g√• p√• i tilsynstabellen er `postnr`, mens kommune-dataen v√•r bare har info om kommunenavn og kommunenummer. Heldigvis har vi en fil i GCS, `postnummer`, som kan hjelpe oss med √• knytte de to tabellene sammen!

Vi √∏nsker √• gj√∏re akkurat det samme for `postnummer` som vi gjorde for tilsyn: 
1. Initiere tabellen med riktige antall kolonner og typer
2. Kopier fra stage-objekt til tabell
3. Verifiser resultatet

<details>
  <summary>üö® L√∏sningsforslag</summary>

```sql
-- Initier postnummer-tabell 
CREATE TABLE postnummer (
    postnummer VARCHAR,
    poststed VARCHAR,
    kommunenummer VARCHAR,
    kommunenavn VARCHAR
);

-- Kopier postnummer fra stage til Snowflake-tabell
COPY INTO postnummer 
FROM @gcp_data/csv/postnummer.csv
file_format=csv_format
on_error=continue;
```
  
</details>


## DEL 3: Hent og transformer JSON-data for kommuner üó∫Ô∏è

CSV-filene vi har jobbet med hittil har v√¶rt enkel, tabul√¶r data. Men hvordan h√•ndterer man semi-strukturert data som JSON?

### Oppgave 3.1: Last opp data fra stage til kommuner-tabell

Som i tidligere oppgaver m√• vi starte med √• initiere tabellen v√•r. I kodesnutten under lager vi tabellen `kommuner` med all data i √©n kolonne av typen `VARIANT`. Det er en fleksibel datatype som kan holde en hvilken som helst type av semi-strukturerte data som JSON, Avro, XML eller lignende. Kj√∏r kodesnutten under:

```sql
CREATE TABLE kommuner (
    json_data variant
);
```

Deretter m√• vi kopiere inn dataen fra GCS p√• samme m√•te som f√∏r. Det eneste vi dropper √• gj√∏re er √• lage et filformat slik som for CSV, da det eneste vi trenger √• sette er typen:

```sql
COPY INTO kommuner
from @gcp_data/json/kommuner.json
file_format = (type = JSON);
```

Ta en titt p√• tabellen vi n√• har opprettet. Her er vi n√∏dt til √• n√∏ste opp i et par ting üßπ

### Oppgave 3.2: Pakk ut JSON-data

La oss starte med √• pakke ut dataen slik at vi f√•r √©n kommune per rad. Vi bruker en noe mystisk funksjon, `LATERAL FLATTEN`, for √• pakke ut features-objektet. Det er den mest effektive m√•te √• pakke ut n√∏stede arrays i en JSON-kolonne, slik vi har her:

```sql
CREATE TABLE kommuner_unwrapped as 
    select f.value as feature
    from kommuner,
    lateral flatten(input => kommuner.json_data[0]:features) f;
```

Se p√• den nye tabellen v√•r. N√• har vi i alle fall √©n rad per feature (kommuner med data), men vi √∏nsker √• pakke ut dataen enda mer fra JSON-formatet til kolonner. 

Det vi trenger fra kommuner er kommunenavn, kommunenummer og geometri slik at vi kan sl√• det sammen med de andre tabellene og plotte tilsynskarakterene i et kart per kommune. Vi √∏nsker i samme slengen √• transformere geometry-objektet til bin√¶r-format, og det kan du gj√∏re ved √• bruke `ST_ASWKB(TRY_TO_GEOMETRY(feature:geometry))`. 

Finn ut av hvordan vi kan f√• transformert JSON-objektet til de √∏nskede kolonnene og pr√∏v selv!

<details>
  <summary>üö® L√∏sningsforslag</summary>


  I Snowflake aksesserer du JSON-objekter med kolon, `:`. Hvis du for eksempel har `{"key": "value"}` i en kolonne, `json_column`, s√• kan du hente ut verdien med `json_column:key::<TYPE>`, der `TYPE` er typen du √∏nsker √• konvertere til (eksempelvis `STRING`). For n√∏stede objekter kan du bare fortsette med den samme annotasjonen (eksempelvis `{ "outer": { "inner": "value" } }` blir `json_column:outer:inner::<TYPE>`). 

```sql
CREATE TABLE kommuner_transformert as
    select  
        feature:properties:kommunenavn::STRING as kommunenavn,
        feature:properties:kommunenummer::STRING as kommunenummer,
        ST_ASWKB(TRY_TO_GEOMETRY(feature:geometry)) AS geometry
    from kommuner_unwrapped;
```
  
</details>

### Oppgave 3.3: Sl√• sammen datasettene

N√• har vi all dataen vi trenger p√• formatet vi √∏nsker! Det siste vi da m√• gj√∏re er √• sl√• sammen datasettene. 
Som nevnt tidligere trenger vi postnummer-tabellen til √• knytte tilsynsdata og kommuner sammen. For √• oppn√• m√•let v√•rt trenger vi f√∏lgende kolonner: 

1. `navn`, `dato` og `total_karakter` fra `tilsyn_transformert`-tabellen
3. `kommunenavn`, `kommunenummer` og `geometry` fra `kommuner_transformert`-tabellen

Gj√∏r et fors√∏k selv!

> **Tips üí°** Dette kan fort bli en lang sp√∏rring, s√• det kan v√¶re lurt √• dele opp joins i hver sin delsp√∏rring ved bruk av `WITH <navn_p√•_delsp√∏rring> AS ...` og deretter bruke `<navn_p√•_delsp√∏rring>` i neste join. Du kan lese mer om `WITH`-clauses [her](https://www.geeksforgeeks.org/sql-with-clause/).

<details>
  <summary>üö® L√∏sningsforslag</summary>
    
```sql
CREATE TABLE tilsyn_med_kommune as (
  WITH tilsyn_med_postnummer as (
    SELECT 
      t.navn,
      t.dato,
      t.total_karakter,
      p.*
    FROM postnummer as p 
    JOIN tilsyn_transformert as t
    ON t.postnr = p.postnummer
  )
  SELECT 
    t.navn,
    t.dato,
    t.total_karakter, 
    t.postnummer,
    t.poststed,
    k.*
  FROM kommuner_transformert as k 
  LEFT JOIN tilsyn_med_postnummer as t
  ON k.kommunenummer = t.kommunenummer
);
```

</details>


Ta en titt p√• dataen n√•. N√• har vi egentlig all data vi trenger til √• plotte tilgjengelig!

## DEL 4: Grupper data p√• kommuner og plott resultatet üìä

### Oppgave 4.1: Karaktersnitt per kommune

Tabellen v√•r `tilsyn_med_kommune` har n√• √©n rad per tilsyn. Det vi n√• trenger √• gj√∏re er √• gruppere dataen slik at vi har en gjennomsnittskarakter p√• hver kommune. Lag en sp√∏rring som tar med `kommunenavn`, `geometry`, og gjennomsnittskarakteren av `total_karakter` (avrundet med tre desimaler). Kall den nye tabellen `tilsynskarakter_per_kommune`. 

<details>
  <summary>üö® L√∏sningsforslag</summary>

```sql
CREATE TABLE tilsynskarakter_per_kommune as 
    SELECT 
        kommunenavn,
        kommunenummer,
        geometry,
        round(avg(total_karakter), 3) as gjennomsnittlig_karakter
    FROM tilsyn_med_kommune
    GROUP BY kommunenavn, kommunenummer, geometry;
```
  
</details>

Kj√∏r en `SELECT` p√• den nye tabellen din og naviger deg til h√∏yre kolonne i resultatet. Scroller du nedover finner du mer detaljert info om `gjennomsnittlig_karakter`-kolonnen, som gjennomsnittlig karakter for alle kommuner, distribusjonen av karakterer og prosentvis null-verdier. Vi ser at kolonneverdiene er relativt normaldistribuert, s√• her blir det kult √• plotte!  


### Oppgave 4.2: Plott tilsynskarakter per kommune 
N√• skal vi ta i bruk dataene vi har laget via en snowflake-connector. En connector lar deg koble til Snowflake utenfor plattformen via f.eks en Python-applikasjon. Vi har allerede laget et Python-script for √• visualisere dataene i `tilsynskarakter_per_kommune`-tabellen. Scriptet konverterer geometrikolonnen tilbake til GeoJSON fra bin√¶rformat. Dette m√• til for √• kunne visualisere dataene i rammeverket `Folium`. Slik gj√∏r du det:

1. For √• kunne kj√∏re scriptet m√• du f√∏rst klone repoet
```sh
git clone git@github.com:bekk/snowflake-workshop.git
```

2. Av erfaring varierer Python noe fra maskin til maskin, s√• jeg anbefaler at dere lager et _virtual environment_ i repoet du nettopp klonet:
```sh
python3 -m venv .venv && source .venv/bin/activate
```

3. Deretter m√• du installere avhengighetene som trengs. Dette gj√∏r du ved √• navigere deg inn i `/visualisering` og kj√∏re
```sh
pip install -r requirements.txt
```

4. Etter √• ha installert avhengighetene m√• du sette inn de n√∏dvendige parameterene i `main.py`. Finn frem brukernavnet, passordet, database- og skjema-navnet. Fyll disse inn i `connector.connect`-funksjonen.

N√•r parametererne er ferdig utfylt kj√∏rer du f√∏lgende kommando i `/visualisering`-mappen

```sh
python main.py
```

Etter kommandoen er ferdigkj√∏rt vil det bli laget en fil `map.html`. √Öpne opp filen i en nettleser og du vil se dataene dine plottet p√• et kart.

Gratulerer - n√• kan du vite hvilke kommuner du b√∏r - og absolutt _ikke_ b√∏r - bes√∏ke om du er p√• jakt etter en kulinarisk opplevelse üçî

## DEL 5: Transformasjoner i dbt

Frem til n√• har vi kj√∏rt transformasjonene v√•re manuelt i et worksheet. Dette er ikke s√¶rlig skalerbart n√•r man jobber p√• prosjekt. Derfor √∏nsker vi √• ta i bruk **dbt**!

**dbt** (data build tool)
