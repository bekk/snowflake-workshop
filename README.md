# Workshop: Introduksjon til Snowflake ‚ùÑÔ∏è

Velkommen til Snowflake-workshop! De neste to timene skal vi bryne oss p√• innhenting, transformering og plotting av [tilsynsdata](https://hotell.difi.no/?dataset=mattilsynet/smilefjes/tilsyn) fra Digitaliseringsdirektoratet. Dette er en vurdering av over 3500 restauranter i Norge p√• parametre som lokaler, math√•ndtering, merking og lignende. V√•rt m√•l er √• ta i bruk geodata fra Kartverket for √• visualisere hvilke kommuner i Norge som ikke har restaurantene sine helt p√• stell üòÄ ü§î üò©

## DEL 1: Kobling mot Google Cloud Storage üíæ

Logg inn p√• [Snowflake](https://ae44471.europe-west4.gcp.snowflakecomputing.com/console/login#/) med brukernavn og passord du har blitt tildelt og naviger deg til **Projects -> Worksheets** og lag et nytt worksheet i h√∏yre hj√∏rne. N√• er du klar til √• utvikle i ditt eget arbeidsomr√•de!

### Oppgave 1: Lag database og skjema 
Det f√∏rste du m√• gj√∏re er √• lage en egen database og skjema (datasett) p√• formatet `ditt_navn`_database/schema slik som i kodesnutten under. Bytt med ditt eget navn og kj√∏r cellene i Snowflake. 

```sql
CREATE DATABASE ditt_navn_database; 
CREATE SCHEMA ditt_navn_schema;
```

Naviger deg til **Database** i panelet til venstre og kj√∏r refresh. N√• vil du forh√•pentligvis se at din nye tabell og skjema er opprettet.

<img src=https://github.com/bekk/snowflake-workshop/assets/29883261/6f4f1fac-94f7-43f5-94c0-6bd47b4e4a25 width=250 />

Det er slitsomt √• m√•tte spesifisere hele stien hver gang vi oppretter en tabell. Heldigvis kan du slippe dette ved √• sette hvilken kontekst du √∏nsker √• v√¶re i (alts√•, hvilken database og hvilket skjema du vil bruke). I filen kan du navigere deg i venstre hj√∏rne og sette database og skjema som vi akkurat lagde.

<img src=https://github.com/bekk/snowflake-workshop/assets/29883261/baac22e4-51e6-415c-98fb-02cf5ba46c44 width=400 />


Nok snikksnakk, la oss hente data fra GCP!

### Oppgave 2: Last inn data fra GCS-b√∏tte ü™£

N√• skal vi hente data fra `snowflake-ws-raw-data`-b√∏tta som ligger i [GCP](https://console.cloud.google.com/storage/browser?project=snowflake-workshop&prefix=&forceOnBucketsSortingFiltering=true). For √• gj√∏re dette er vi n√∏dt til √• opprette en konfigurasjonsenhet som brukes for √• integrere Snowflake med eksterne lagringstjenester (som Google Cloud Storage). Denne enheten kalles for `storage integration object` og oppretter blant annet en egen service account (maskinbruker) som vi kan gi tilgang til i b√∏tta v√•r. Kodesnutten under sier at vi √∏nsker √• lage et eksternt volum i GCS som har tilgang til en gitt sti.

Kopier og kj√∏r den i fila di:

```sql
CREATE STORAGE INTEGRATION gcp_integration
    type = external_stage
    storage_provider = GCS 
    enabled = true 
    storage_allowed_locations = ('gcs://snowflake-ws-raw-data/');
```

N√• kan vi hente ut den genererte maskinbrukeren ved √• kj√∏re:

```sql
DESC STORAGE INTEGRATION gcp_integration;
```

Kopier navnet p√• `STORAGE_GCP_SERVICE_ACCOUNT`, naviger deg til [**Permissions**](https://console.cloud.google.com/storage/browser/snowflake-ws-raw-data;tab=permissions?forceOnBucketsSortingFiltering=true&project=snowflake-workshop&prefix=&forceOnObjectsSortingFiltering=false)-fanen i b√∏tta og gi maskinbrukeren rettigheten `Storage Admin`.

S√• lett var det - n√• har vi muligheten til √• autentisere oss mot b√∏tta og hente ut dataen üöÄ

### Oppgave 3: Lag mellomledd for kildedata og datavarehus

Det siste vi trenger √• lage for √• hente data er et `stage object`. Dette er et omr√•de som brukes til midlertidig lagring av r√•datafiler f√∏r de lastes inn i Snowflake-databaser. Det fungerer som et mellomledd mellom kildedataene og datavarehuset v√•rt. For √• hente dataen m√• vi ta i bruk `storage integration`-objektet vi nettopp lagde ved √• kopiere og kj√∏re kodesnutten under:

```sql
CREATE STAGE gcp_data
    storage_integration = gcp_integration
    url = 'gcs://snowflake-ws-raw-data/';
```

Verifiser at dette funket ved √• kj√∏re `list @gcp_data;`. F√•r du opp fire filer, er vi _endelig_ klare til √• kopiere data inn i Snowflake. 


## DEL 2: Hent CSV-data for tilsyn og postnummer üì´

### Oppgave 1: Kopier data fra stage til tabell
N√• skal vi gj√∏re oss klare for √• laste inn data. F√∏rst er vi n√∏dt til √• lage et fil-format som matcher CSV-formatet. Hvis vi √•pner `postnummer.csv` og `tilsyn.csv` i b√∏tta v√•r ser vi at vi har √©n header med semikolon-separerte verdier. Dette m√• vi ta h√∏yde for, slik som i kodesnutten under:

```sql
CREATE FILE FORMAT csv_format
    type = csv 
    field_delimiter = ';'
    skip_header = 1;
```

I tillegg m√• vi initiere tabellen v√•r, `tilsyn`, med riktig antall kolonner og type. Dette er en d√∏ll prosess √• gj√∏re for h√•nd (ChatGPT fikset det for meg), s√• bare kopier og kj√∏r snutten under:

```sql
CREATE TABLE tilsyn (
    tilsynsobjektid VARCHAR,
    orgnummer VARCHAR,
    navn VARCHAR,
    adrlinje1 VARCHAR,
    adrlinje2 VARCHAR,
    postnr VARCHAR,
    poststed VARCHAR,
    tilsynid VARCHAR,
    sakref VARCHAR,
    status INT,
    dato VARCHAR,
    total_karakter INT,
    tilsynsbesoektype INT,
    tema1 VARCHAR,
    tema1_nn VARCHAR,
    karakter1 INT,
    tema2_no VARCHAR,
    tema2_nn VARCHAR,
    karakter2 INT,
    tema3_no VARCHAR,
    tema3_nn VARCHAR,
    karakter3 INT,
    tema4_no VARCHAR,
    tema4_nn VARCHAR,
    karakter4 INT
);
```

Til slutt kopierer vi dataen _fra_ stage-objektet v√•rt _til_ den nylig opprettede tabellen v√•r. Merk at n√•r vi tar i bruk stage-objektet v√•rt, s√• slipper vi ogs√• √• fore inn hele URL-en. Siden dataen ogs√• (muligens) inneholder noen korrupte rader, slenger vi p√• `on_error=continue` for at opplastingen skal hoppe over disse radene og fortsette innlastningen. Kj√∏r og kopier:

```sql
COPY INTO tilsyn 
FROM @gcp_data/csv/tilsyn.csv
file_format=csv_format
on_error=continue;
```

Kj√∏r en sp√∏rring p√• tabellen for √• sjekke at dataen er korrekt lastet inn. 

### Oppgave 3: Transformer tilsynstabellen

Det er et par ting med den opprinnelige r√•dataen som ikke passer v√•rt form√•l. Lag derfor en sp√∏rring og skriv den til en ny tabell, `tilsyn_transformert`, som inneholder f√∏lgende:
1. `navn, orgnummer, postnr, poststed, totalkarakter`-kolonnene p√• vanlig format
2. Sette verdier fra `karakter1` til kolonne `rutiner_og_ledelse`, `karakter2` til `lokaler_og_utstyr`, `karakter3` til `mathandtering_og_tilberedning` og `karakter4` til `merking_og_sporbarhet`
3. Omgj√∏re dato-strengen p√• formatet 'DDMMYYYY' til dato 

<details>
  <summary>üö® L√∏sningsforslag</summary>
  
  ```sql
  CREATE TABLE tilsyn_transformert as 
      select 
          navn, 
          orgnummer,
          postnr, 
          poststed,
          total_karakter,
          karakter1 as rutiner_og_ledelse,
          karakter2 as lokaler_og_utstyr,
          karakter3 as mathandtering_og_tilberedning,
          karakter4 as merking_og_sporbarhet,
          TO_DATE(dato, 'DDMMYYYY') as dato
      from tilsyn;
  ```

</details>

Kj√∏r en sp√∏rring som verifiserer at dataen ser korrekt ut


### Oppgave 4: Hent inn postnummer-data

I neste del av workshopen skal vi f√• inn geodata for kommuner. Problemet v√•rt er at det eneste vi har √• g√• p√• i tilsynstabellen er `postnr`, mens kommune-dataen v√•r bare har info om kommunenavn og kommunenummer. Heldigvis har vi en fil i GCS, `postnummer`, som kan hjelpe oss med √• knytte de to tabellene sammen!

Vi √∏nsker √• gj√∏re akkurat det samme for `postnummer` som vi gjorde for tilsyn: 
1. Initiere tabellen med riktige antall kolonner og typer
2. Kopier fra stage-objekt til tabell
3. Verifiser resultatet

Gj√∏r dette i Snowflake.  

<details>
  <summary>üö® L√∏sningsforslag</summary>

```sql
-- Initier postnummer-tabell 
CREATE TABLE postnummer (
    postnummer VARCHAR,
    poststed VARCHAR,
    kommunenummer VARCHAR,
    kommunenavn VARCHAR
);

-- Kopier postnummer fra stage til Snowflake-tabell
COPY INTO postnummer 
FROM @gcp_data/csv/postnummer.csv
file_format=csv_format
on_error=continue;
```
  
</details>


## DEL 3: Hent og transformer JSON-data for kommuner üó∫Ô∏è

CSV-filene vi har jobbet med hittil har v√¶rt enkel, tabul√¶r data. Men hvordan h√•ndterer man semi-strukturert data som JSON?

### Oppgave 1: Last opp data fra stage til kommuner-tabell

Som i tidligere oppgaver m√• vi starte med √• initiere tabellen v√•r. I kodesnutten under lager vi tabellen `kommuner` med all data i √©n kolonne av typen `VARIANT`. Det er en fleksibel datatype som kan holde en hvilken som helst type av semi-strukturerte data som JSON, Avro, XML eller lignende. Kj√∏r kodesnutten under:

```sql
CREATE TABLE kommuner (
    json_data variant
);
```

Deretter m√• vi kopiere inn dataen fra GCS p√• samme m√•te som f√∏r. Det eneste vi dropper √• gj√∏re er √• lage et filformat slik som for CSV, da det eneste vi trenger √• sette er typen:

```sql
COPY INTO kommuner
from @gcp_data/json/kommuner.json
file_format = (type = JSON);
```

Ta en titt p√• tabellen vi n√• har opprettet. Her er vi n√∏dt til √• n√∏ste opp i et par ting üßπ

### Oppgave 2: Pakk ut JSON-data

La oss starte med √• pakke ut dataen slik at vi f√•r √©n kommune per rad. Vi bruker en noe mystisk funksjon, LATERAL FLATTEN, for √• pakke ut features-objektet. Det er den mest effektive m√•te √• pakke ut n√∏stede arrays i en JSON-kolonne, slik vi har her:

```sql
CREATE TABLE kommuner_unwrapped as 
    select f.value as feature
    from kommuner,
    lateral flatten(input => kommuner.json_data[0]:features) f;
```

Se p√• den nye tabellen v√•r. N√• har vi i alle fall √©n rad per feature (kommuner med data), men vi √∏nsker √• pakke ut dataen enda mer fra JSON-formatet til kolonner. 

I Snowflake aksesserer du JSON-objekter med kolon, `:`. Hvis du for eksempel har `{"key": "value"}` i en kolonne, `json_column`, s√• kan du hente ut verdien med `json_column:key::<TYPE>`, der `TYPE` er typen du √∏nsker √• konvertere til (eksempelvis `STRING`). For n√∏stede objekter kan du bare fortsette med den samme annotasjonen (eksempelvis `{ "outer": { "inner": "value" } }` blir `json_column:outer:inner::<TYPE>`). 

Det vi trenger fra kommuner er kommunenavn, kommunenummer og geometri slik at vi kan sl√• det sammen med de andre tabellene og plotte tilsynskarakterene i et kart per kommune. Vi √∏nsker i samme slengen √• transformere geometry-objektet til bin√¶r-format, og det kan du gj√∏re ved √• bruke ST_ASWKB(TRY_TO_GEOMETRY(feature:geometry)). Pr√∏v deg p√• transformasjonen selv!

<details>
  <summary>üö® L√∏sningsforslag</summary>

```sql
CREATE TABLE kommuner_transformert as
    select  
        feature:properties:kommunenavn::STRING as kommunenavn,
        feature:properties:kommunenummer::STRING as kommunenummer,
        ST_ASWKB(TRY_TO_GEOMETRY(feature:geometry)) AS geometry
    from kommuner_unwrapped;
```
  
</details>


N√• har vi all dataen vi trenger p√• formatet vi √∏nsker! Det siste vi da m√• gj√∏re er √• sl√• sammen datasettene. Kodesnutten under sl√•r f√∏rst sammen tilsyn med kommuner, f√∏r vi deretter sl√•r sammen resultatet fra sp√∏rringen med kommune-dataen:

```sql
CREATE TABLE tilsyn_med_kommune as (
  WITH tilsyn_med_postnummer as (
    SELECT 
      t.navn,
      t.dato,
      t.total_karakter,
      p.*
    FROM postnummer as p 
    JOIN tilsyn_transformert as t
    ON t.postnr = p.postnummer
  )
  SELECT 
    t.navn,
    t.dato,
    t.total_karakter, 
    t.postnummer,
    t.poststed,
    k.*
  FROM kommuner_transformert as k 
  LEFT JOIN tilsyn_med_postnummer as t
  ON k.kommunenummer = t.kommunenummer
);
```

Ta en titt p√• dataen n√•. N√• har vi egentlig all data vi trenger til √• plotte tilgjengelig!

## DEL 4: Grupper data p√• kommuner og plott resultatet üìä

### Oppgave 1: Karaktersnitt per kommune

Tabellen v√•r `tilsyn_med_kommune` har n√• √©n rad per tilsyn. Det vi n√• trenger √• gj√∏re er √• gruppere dataen slik at vi har en gjennomsnittskarakter p√• hver kommune. Lag en sp√∏rring som tar med `kommunenavn, kommunenummer, geometry`, og gjennomsnittskarakteren av `total_karakter` (avrundet med tre desimaler). 

<details>
  <summary>üö® L√∏sningsforslag</summary>

```sql
CREATE TABLE tilsynskarakter_per_kommune as 
    SELECT 
        kommunenavn,
        kommunenummer,
        geometry,
        round(avg(total_karakter), 3) as gjennomsnittlig_karakter
    FROM tilsyn_med_kommune
    GROUP BY kommunenavn, kommunenummer, geometry;
```
  
</details>

Kj√∏r en `SELECT` p√• den nye tabellen din og naviger deg til h√∏yre kolonne i resultatet. Scroller du nedover finner du mer detaljert info om `gjennomsnittlig_karakter`-kolonnen, som gjennomsnittlig karakter for alle kommuner, distribusjonen av karakterer og prosentvis null-verdier. Vi ser at kolonneverdiene er relativt normaldistribuert, s√• her blir det kult √• plotte!  


### Oppgave 2: Plott tilsynskarakter per kommune
